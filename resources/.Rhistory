knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(dplyr)
library(dplyr)
library(readr)
data_unique_id_subset <- read_csv("data_unique_id_subset.csv")
data_unique_id_subset <- read_csv("data_unique_id_subset.csv")
data_age_gender_subset <- read_csv("data_age_gender_subset.csv")
data_amp_summary_subset <- read_csv("data_amp_summary_subset.csv")
data_selfreport_summary_subset <- read_csv("data_selfreport_summary_subset.csv")
data_combined <- data_amp_summary_subset|> full_join(data_age_gender_subset, by = "unique_id")
data_self_reports_and_their_amp_data <- data_selfreport_summary_subset |> left_join(data_amp_summary_subset, by = "unique_id")
?left_join
combined_ids <- data_age_gender_subset |>
select(unique_id) |>
full_join(data_amp_summary_subset |> select(unique_id), by = "unique_id") |>
full_join(data_selfreport_summary_subset |> select(unique_id), by = "unique_id") |>
distinct()
data_missing_ids <- combined_ids |>
anti_join(data_unique_id_subset, by = "unique_id")
View(data_missing_ids)
View(data_combined)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
library(dplyr)
library(tidyr)
library(readr)
library(janitor) # for clean_names()
library(stringr)
# # demographics
data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |> janitor::clean_names()
# # demographics
data_demographics_raw_messy <- read_csv("../data/raw/data_demographics_raw_messy.csv", skip = 2) |> janitor()
data_demographics_raw <- read_csv("../data/raw/data_demographics_raw.csv") |>
janitor::clean_names()
# self report measure
data_selfreport_raw <- read_csv("../data/raw/data_selfreport_raw.csv") |>
janitor::clean_names()
# affect attribution procedure
data_amp_raw <- read_csv("../data/raw/data_amp_raw.csv") |>
janitor::clean_names()
# do we have duplicate data?
data_demographics_raw |>
count(subject) |>
arrange(desc(n))
dat_unique_id <- data_demographics_raw |>
rename(unique_id = subject) |>
count(unique_id) |>
filter(n == 2) |>
select(unique_id)
# wrangle the age data out of the raw
dat_age <- data_demographics_raw |>
# rename for clarity
rename(unique_id = subject, item = trialcode) |>
# select useful columns
select(unique_id, item, response) |>
# retain rows that we need
filter(item == "age") |>
rename(age = response) |>
# remove non-numbers or decimals from age
mutate(age = str_remove_all(age, "[^\\d.]"),  # retains only digits and decimal points
age = na_if(age, ""),
age = as.numeric(age)) |>
select(unique_id, age)
# wrangle the gender data out of the raw
dat_gender <- data_demographics_raw |>
# rename for clarity
rename(unique_id = subject, item = trialcode) |>
# select useful columns
select(unique_id, item, response) |>
# retain rows that we need
filter(item == "gender") |>
rename(gender = response) |>
# remove non-numbers or decimals from age
mutate(gender = str_to_lower(gender),
gender = str_remove_all(gender, "[\\d.]"),
gender = na_if(gender, ""),
gender = case_when(gender == "woman" ~ "female",
gender == "yes" ~ NA_character_,
gender == "man" ~ "male",
gender == "girl" ~ "female",
gender == "dude" ~ "male",
gender == "non binary" ~ "non-binary",
TRUE ~ gender)) |>
select(unique_id, gender)
View(data_amp_raw)
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id= subject) |>
select(unique_id, latency)
View(data_amp_performance_criteria)
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt)
View(data_amp_performance_criteria)
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test") |>
#mutate(fast_trial = rt <100) gives you t4rue or false
mutate(fast_trial = ifelse(rt < 100, 1, 0))
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test") |>
#mutate(fast_trial = rt <100) gives you t4rue or false
mutate(fast_trial = ifelse(rt < 100, 1, 0)) |>
summarise( percent_fast_trials = mean(fast_trial) * 100) #squashes rows together gives you in this case the percentage of the trials onder 100ms
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test") |>
#mutate(fast_trial = rt <100) gives you t4rue or false
mutate(fast_trial = ifelse(rt < 100, 1, 0)) |>
group_by(unique_id) |> # to give the percentage for every person instead of one row representingall
summarise( percent_fast_trials = mean(fast_trial) * 100) #squashes rows together gives you in this case the percentage of the trials onder 100ms
View(data_amp_raw)
#
data_amp_tidied |>
count(unique_id, name = "n_participant") |>
count(n, name= "n_trials") |>
arrange(desc(n_participants))
#lets check for duplicates, basic tidying
data_amp_tidied <- data_amp_raw|>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test")
#
data_amp_tidied |>
count(unique_id, name = "n_participant") |>
count(n, name= "n_trials") |>
arrange(desc(n_participants))
# are there duplicates or incomplete data
data_amp_tidied |>
count(unique_id, name = "n_participants") |>
count(n, name= "n_trials") |>
arrange(desc(n_participants))
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test") |>
#mutate(fast_trial = rt <100) gives you t4rue or false
mutate(fast_trial = ifelse(rt < 100, 1, 0)) |>
group_by(unique_id) |> # to give the percentage for every person instead of one row representingall
summarise( percent_fast_trials = mean(fast_trial) * 100) #squashes rows together gives you in this case the percentage of the trials onder 100ms
View(data_amp_tidied)
# are there duplicates or incomplete data
data_amp_tidied |>
count(unique_id, name = "n_participants") |>
count(n, name= "n_trials") |>
arrange(desc(n_participants))
# are there duplicates or incomplete data
data_amp_tidied |>
count(unique_id, name = "n_participants") |>
count(n_trials, name= "n_trials") |>
arrange(desc(n_participants))
# are there duplicates or incomplete data
data_amp_tidied |>
count(unique_id, name = "n_trials") |>
count(n_trials, name= "n_participants") |>
arrange(desc(n_participants))
temp <- data_amp_tidied|>
count(unique_id, name = "n_trials") |>
filter(n_trials == 72)
View(temp)
data_complete_amp <- data_amp_tidied|>
count(unique_id, name = "n_trials") |>
filter(n_trials == 72) |>
temp<-
data_amp_performance_criteria <- data_amp_raw |>
rename(unique_id = subject,
block_type = blockcode,
rt = latency) |>
select(unique_id, block_type, rt) |>
filter(block_type == "test") |>
#mutate(fast_trial = rt <100) gives you t4rue or false
mutate(fast_trial = ifelse(rt < 100, 1, 0)) |>
group_by(unique_id) |> # to give the percentage for every person instead of one row representingall
summarise( percent_fast_trials = mean(fast_trial) * 100) #squashes rows together gives you in this case the percentage of the trials onder 100ms
View(temp)
temp<- data_amp_tidied |>
semi_join(data_complete_amp, by= "unique_id")
data_complete_amp <- data_amp_tidied|>
count(unique_id, name = "n_trials") |>
filter(n_trials == 72)
temp<- data_amp_tidied |>
semi_join(data_complete_amp, by= "unique_id")
View(temp)
#are there duplicates or incomplete data?
# sanity check should have one row
data_amp_tidied_complete|>
count(unique_id, name = "n_trials") |>
count(n_trials, name= "n_participants") |>
arrange(desc(n_participants))
data_amp_tidied_complete<- data_amp_tidied |>
semi_join(data_complete_amp, by= "unique_id") #only participants with the right ammount of trials
#are there duplicates or incomplete data?
# sanity check should have one row
data_amp_tidied_complete|>
count(unique_id, name = "n_trials") |>
count(n_trials, name= "n_participants") |>
arrange(desc(n_participants))
View(data_amp_tidied_complete)
